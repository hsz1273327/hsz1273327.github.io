---
layout: post
title: "AIPC折腾记"
series:
    aipc_experiment:
        index: 1
date: 2024-11-08
author: "Hsz"
category: experiment
tags:
    - AIPC
header-img: "img/home-bg-o.jpg"
update: 2025-10-09
---
# AIPC折腾记

2023年末因特尔提出了一个"AIPC"的概念.各大科技公司纷纷响应仿佛迎来了了一股新风潮.

根据目前业界的讨论和定义,一个设备要被称为AI PC通常需要满足以下几个标准:

1. 内嵌个人大模型: 需要有能力内嵌本地大语言模型
2. 本地混合AI算力: 硬件上需要有CPU,GPU,NPU等混合AI算力设备
3. 自然语言交互: 用户能够通过自然语言与设备进行交互

那很自然的,这个AIPC的概念是配合最近人工智能领域大语言模型(llm)的崛起而提出的.有价值么?有,虽然现在的LLM水平大致和文科本科生差不多,但如果你对它的期望没那么大,配合本地知识库构造agent还是多少能帮点忙的.

这个概念提出的时候是针对笔记本电脑的,对AI应用的定位也是`个人助理`,因此标准中会混入`NPU`这种目标是低成本低功耗的算力设备,但实际情况是就目前(2024年底)的大语言模型来说,参数规模过大,[现有npu算力根本连7b规模的模型都无法流畅运行(感谢b站网友的测试)](https://www.bilibili.com/video/BV1jsYsezEp7/?vd_source=08b668b29d50d7b81093d4adee9dfde0),而且功耗也不低.要提高功耗提高算力那必然需要脱离移动端,不用npu,gpu就能干而且成本就上来了.因此某种意义上来说狭义的AIPC这个概念在目前(2024年底)还是个伪命题.

那还折腾个什么劲儿呢?

我们不妨将限制放松.如果我们将AIPC的概念定位从`个人助理`扩展到`团队助理`或`家庭助理`,将AIPC的设备定义从移动端笔记本换成工作站,小型服务器,标准都不用变这个概念似乎就能活过来了.

那相对于移动端来说就会需要一些概念上的迁移和交互上的变化:

+ 对于工作站来说,它依然是一个端侧概念,但拥有更强的算力和更大的存储空间,可以部署更大规模的模型和知识库,同时可以承担更多的任务.这也就意味着虽然这种形式依然是针对单一用户,但更加偏向于垂直领域的生产力助理的角色.因此可能需要有一定程度的模型定制化能力(finetune能力).

+ 对于小型服务器来说,它可以是一个局域网内的边缘.服务器的角色就相当于边缘计算中的上位机,仅作为输入输出网关和计算中心,知识库可以是专门的nas从而解耦避免珍贵数据的丢失;有服务端就需要有客户端,同时也就设计到多用户的权限管理和数据隔离问题.这也就意味着这种用法在部署本地模型和rag相关组件外还会有额外的开发成本.

这两个方向都会涉及到大模型推理之外的开发工作.还好我略微会一点开发,这个还是可以搞的定的.

也就是说我们可以开发一个家庭助理agent,它可以在有本地网络的情况下优先使用部署在家里的小型服务器上的常驻模型,如果没有网络或者模型无法满足需求时再使用本地算力,如果本地算力也无法满足需求时再使用云端供应商提供的模型api.这样就可以最大程度的利用本地资源同时又不失灵活性.

之所以要折腾这套aipc我也不是没有目的的.我的期望是可以做一套家庭助手服务,主要解决如下问题

1. 非关键照片,视频等资料的整理和查找问题.家里nas虽然有照片功能,但至少我家这边看来并不好用.
2. 编程辅助,我希望为自己搭建一个符合个人习惯和风格的编程助理.它需要熟识我的工作流和技术栈,并且可以随着自己的技能更新同步进化
3. 儿童辅导,我希望构造一个家庭教师一般的ai,可以给小孩上学做辅导,布置作业,批改作业,教授扩展知识等.

可以看到这些都是相当私人的需求,使用的数据也会有很多都是家里的私有数据.因此需要本地模型,这也才有了AIPC的用武之地.当然如果上面的都能实现,那想来家庭医生,私人法律顾问这类也应该没有什么难度,那自然也是可以搞的,如果设计得当,可以作为一个通用的家庭助手agent平台,满足很多非标准需求.

本文的主要工作是记录折腾AIPC过程中用到的核心组件.


## AMD Ryzen 7 8700G

早在2024年初,amd就发售了8700g这块zen4架构的apu.当时2400的售价确实有点高不可攀.但我们都知道amd的cpu首发从来都是高溢价的,在半年多后的今天果然盒装掉到了1800元左右,散片到了1600元左右.个人认为已经到了一个可以接受的范围因此入了一块回来折腾.

### 基本规格

首先介绍下[这颗apu的基本规格](https://www.amd.com/zh-cn/products/processors/desktops/ryzen/8000-series/amd-ryzen-7-8700g.html).这颗u可以认为是7840hs的am5接口封装版本

+ Zen 4架构,8核16线程的全大核配置
+ CPU默认主频4.2GHz,睿频5.1GHz,二级缓存8m,三级缓存16m,TDP为65W,最小保证功耗为45W
+ 配备核显是780m,2900MHz,fp16算力5.5 TFLOPS,支持vulkan,第三方支持rocm,和cpu共享内存96 GB/s的带宽(双通道6000MHZ ddr5)
+ 配备16 TOPS的int4精度算力的npu,但目前没有生态支持
+ 配备PCIe通道总共20条,其中16条可直连,额外4条分配给芯片组
+ 使用am5接口分装,可以使用在600系,800系主板上,单die使用硅脂填充

具体的性能评测可以看[chh上的这篇文章](https://www.chiphell.com/article-31554-1.html)

### 特性分析

这颗u总的来说并不是一颗传统意义上的amd桌面端u,而是一颗APU.可以折腾的点其实比7000系和9000系还多些.我也将围绕这颗U组件平台构造AIPC.这颗U的特点可以看[nga这位网友的总结](https://nga.178.com/read.php?tid=39246196&rand=517),我在下面再额外做些补充

1. 首先是功耗,由于脱胎自移动端,8700g待机功耗15w左右,天然的比同tdp非apu平台的桌面端u待机功耗低(但比不上intel平台).在低功耗区间效能也比同tdp非apu平台的桌面端u强.当然这是有代价的,在高功耗区间比同tdp非apu平台的桌面端还是差不少.而apu没有内置功耗墙,因此如果开pbo一定要设置温度墙或者功耗墙进行限制.

2. 散热友好,由于apu是单die设计,区别于多die的非apu平台的桌面端,apu的die面积更大也就更好压,但由于是硅脂U,虽然比7000系好点,但依然会有积热问题.有评测开盖换液金可以大幅改善积热,但即便不换液金,47mm下压散热器也足以应对.

3. 算力复杂又相互影响,8700g这颗U有cpu,gpu,npu3个部分他们会相互抢电,比如我给核显超频,那在同功率下cpu部分的算力就会比不超核显时差,而pbo会放开功率和电压但最大电流依然会有限制.我们知道ai主要是靠gpu做并行计算,因此我们我们没什么必要给cpu超频,甚至降频可能反而性能更好.至于npu部分,目前npu驱动还没合并进linux内核,也就是说目前在linux下我们调用npu还不太容易,但在下一个版本中该驱动会被合并进主干,到时候我们可以试试.但就目前看B站网友在windows下的评测.这个npu的算力基本属于聊胜于无.

4. 内存频对核显性能有较大影响.一般核显都受限于内存带宽,8000系更是如此,超内存的提升幅度比超核显本身都高.在不超内存不超核显频率的情况下核显性能大致相当于`GTX 1050ti`,如果双超性能大致与`GTX 1650`相当(小超频率到3200,内存异步7500+,1050ti的1.5倍),极限超频可以摸到`GTX 1060`的屁股(1050ti的1.6倍).与之相比的苹果m1大致是`GTX 1050`水平(1050ti的0.75倍),最新的m4大致是`GTX 1060`水平(1050ti的1.6倍).

5. 8000系apu有比非apu桌面处理器更好的if总线带宽,对高频内存支持更好

6. 内存即显存,理论上有多少内存就相当于有多少显存,而现在的模型都普遍很吃显存,这也是为啥考虑用它组aipc的原因.但目前的技术下大内存往往频率超不上去,属于大内存和高频率不可兼得的状态.

7. APU的igpu可用的内存分为显卡专用内存`VRAM`和共享内存`Shared Memory`两部分,一些软件会让核显优先使用`VRAM`,如果不够则去`Shared Memory`中拿资源使用(主要是游戏);一些软件则会仅使用`VRAM`.可以在bios中设置`AMD CBS->NBIO Common Options->GFX Configuration`中设置将一部分内存划给显卡专门使用(VRAM).这个设置的最大值是`16G`.

8. AMD的显卡调用靠rocm(基本是opencl的高级版),而rocm接口只在linux下有完整接口

9. 在linux下我们可以让rocm使用UMA(Unified Memory Architecture)方式让核显访问内存,而这种调用UMA内存的方式默认会使用慢速的细颗粒度内存结构.也就是说要么使用快速但最大16G的VRAM,要么使用慢速但可以全量访问的UMA接口,当然UMA方式访问内存也是可以优化速度的.

**ps**:对统一内存架构感兴趣可以查看[苹果M1统一内存架构真的很厉害吗？从AMD APU的名存实亡谈起（上）](https://www.eet-china.com/news/202108190817.html)和[苹果M1统一内存架构真的很厉害吗？稀松平常的UMA（下）](https://www.eet-china.com/news/202109080900.html)这两篇博文

### apu核显的设置

apu的核显和cpu部分是会抢电的.作为aipc,cpu部分一般都不是瓶颈,我们肯定希望cpu部分在够用的情况下核显尽量的强.这就需要在主板bios中作好针对性的设置.具体的设置我们需要根据主板品牌和cpu体质以及自己的使用需要灵活调整,但总体设置步骤和思路是不变的.设置apu你需要先装好windows,因为

下面是设置步骤和思路.

1. 开起pbo,并给cpu设置温度墙和cpu降压.pbo可以解锁功耗墙,温度墙用于根据机箱散热情况设置以保证工况,cpu降压可以降低cpu部分的功耗和发热,腾出来的空间可以给核显更大的发挥空间.更进一步的可以给cpu定压定频手动降频给核显让路.

2. 给核显超频.核显频率在主板bios的超频部分会有`GFX Clock Frequency`,这里默认是`auto`,我们可以设置为手动然后指定频率,像8700g默认是`2900`,一般超到`3100`都没有问题,我的这颗`3200`没有问题,一些体质好的`3400`也可以.如何确定可以呢,简单说就是超频然后双烤测稳定性,3dmark的timespy测显卡性能,按200一个步进慢慢往上加频率直到不稳定,然后降100,如此往复试出最优

3. 内存超频一般在主板bios的超频部分,会有`xmp`或者`expo`设置,一般是先加载xmp或expo,然后进windows中跑ada64和双烤确保稳定和获取延迟信息,根据情况如果稳定就逐步加频率压时序,不稳定就降频率松时序一直迭代调整指导延迟满意为止.注意apu由于核显的问题需要更大的内存带宽,内存时钟频率(MClk)与内存控制器时钟频率(UClk)之间最好使用2:1模式(异步模式),通过尽量拉高内存频率的方式来增加带宽,而增加频率往往要给内存加压,这会影响内存使用寿命和发热,由于内存一般没有主动散热,因此机箱散热不好的情况下少超.

4. 显存在位置是`AMD CBS->NBIO Common Options->GFX Configuration`,有两种策略,一种是全自动,让系统自行根据负载需要分配,windows下默认会划个最小值(似乎是512M)给VRAM,另一种是手动设置UMA buffer的大小(即最大VRAM的大小).手动设置的流程是
    1. `IGPU Configuration`设置为`UMA_SPECIFIED`
    2. `UMA Frame buffer Size`设置为你希望的大小
    注意`VRAM`被划分后剩下的才是系统可以使用的内存,因此如果你的机器内存比较少最好也少划分点`VRAM`给核显,

### 使用计划

之所以将这块U纳入AIPC的折腾范围主要是看中它的核显.这块APU的核显性能应该是目前(截止到2025年10月)桌面端中最强的了,而且价格也比较合理.它核显的缺陷主要是两点:

+ 算力不行,780m的算力大致相当于1050ti,而且缺少bf16
+ 显存带宽低,受限于内存带宽,超内存超冒烟也就还是个双通道水平,完全无法和独显相比

但它也有优势:

+ 内存即显存,在linux下可以充分利用内存资源
+ 功耗低,发热低,适合长时间运行

我对它的使用计划作为家用微型服务器的主力CPU,配合ddr5的大内存(96G/128G)主要用于利用llama.cpp生态结合vulkan后端跑一些常驻的ai模型:

+ 跑moe模型,moe模型由于其稀疏激活的特性,对显存的容量要求较高,但对算力和显存带宽的要求相对较低,因此非常适合用核显跑.只要优化得当,用96g内存跑30ba3b至80ba3b规模的fp8量化模型应该依然可以控制在16t/s以上,这对于日常使用已经足够了.如果内存足够大,甚至可以跑更大规模的模型.通常性能也够用,完全可以常驻.
+ 跑embedding模型和检索任务,embedding模型通常规模不大,通常这个算力足够,但由于它是rag的核心,因此需要常驻.8700g的核显完全可以胜任这个任务.
+ 跑意图识别模型,意图识别模型通常也不用规模多大的模型,一般4b规模就已经算很足够了,同样的是agent的核心组件,因此也最好常驻,8700g的核显完全可以胜任这个任务.
+ 给nas跑图片打标任务和向量化任务,这个任务通常是离线的,不需要实时响应,因此算力要求不高,但由于图片数据量大,因此对显存容量要求较高,8700g的核显完全可以胜任这个任务.
+ 做共享记忆的载体,虽然每个人的agent都是独立的,但有些记忆是可以共享的,比如家里的照片,视频等资料,一些集体活动的记忆,比较吃空间的知识库等.这些资料放在服务器上,每个人的agent都可以访问,可以作为每个人的agent的记忆扩展.

为什么作为边缘计算的上位机不使用vllm等更高效的推理框架而依然使用一般在端侧使用的llama.cpp呢?主要是因为780m只有fp16和fp32两种精度,而vllm等框架通常需要bf16或int8,int4精度的算力支持.而刚好llama.cpp使用的gguf格式的模型使用的是fp16精度进行计算.

其实不一定是8700g,amd承诺am5接口至少支持到2027年,同时zen5架构的apu在移动端已经发售,目前看其性能相对8700g提升不大(都在默频同内存频率15%左右提升)估计即便有桌面端封装也并不值得特意购入.据说zen6的apu会使用和工作站统一的UDNA架构的核显,改善内存控制器,还会加入x3d技术,如果属实的话只要其性能可以达到3050的水平,到时候就可以入一颗.届时再更新这篇文章.

至于这颗8700g,我给它制定了一个比较长的服役周期,他会分为如下阶段:

1. 基本使用阶段,由于我买的盒装cpu有3年质保,我会在这3年内完全按照官方默认或推荐的方式使用,这个阶段我会为他组一台办公`deskmini`主机,充分利用它的核显,并尽量摸透这颗U在AI方面的能力范围
2. 超频使用阶段,过保后开盖换液金,然后换到itx机箱中提升散热,加装独显并超频使用,我会组一台5L小itx来实现
3. 发挥余热阶段,换回deskmini主机,降压降功耗换90w氮化镓电源当家庭服务器使用

## AMD Ryzen 7 7700

这块zen4的单ccd8核16线程的cpu我是1100元买回来的,单说cpu能力比8700g强,但核显就是亮机卡水平,最好配独显使用.我是拿他放在家里工作站上用的,用来过渡到zen6的单ccd 12核cpu.

### 使用计划

这是一颗过渡cpu,目前用于工作站上.我对它的使用计划是

1. 过渡使用,用到zen6的单ccd 12核cpu发售后合适的时机就换掉它
2. 由于是65w的CPU,而且有个还行的亮机核显,淘汰后可以给家里deskmin用放在单位工作用

## NVIDIA GeForce RTX 4060 Ti 16G

这是一块2023年7月发布的消费级显卡.我买的这块是在2024年7月左右购入了一块耕升的双风扇版丐卡,购入价格为3200.其规格为双槽全高卡,双风扇,长度为20cm.

### 基本规格

介绍下[这块GPU的基本规格](https://www.nvidia.com/zh-tw/geforce/graphics-cards/40-series/rtx-4060-4060ti).

+ 峰值INT8性能为157.3 TOPS
+ 峰值半精度(FP16)性能为 43.1 FLOPS，
+ 16 G GDDR6显存
+ 128-bit的位宽,显存最大带宽288 GB/s
+ 165W的满载功耗
+ 支持PCIe 4.0 x8
+ 支持CUDA,cuDNN,TensorRT等完整的cuda生态

### 特性分析

这块卡算力并不突出,但用于推理足够了,显存16G在消费级显卡中算是比较大的,而且有完整cuda生态,除了50系新出的fp4数据类型外该有的都有,就目前的生态来说无论是生图,跑int8的7B版本大模型或者跑q4的13b版本大模型都是可以的,一些轻量级的finetune技术也可以跑,再加上不错的功耗和发热水平.总的来说,作为入门独显,放在工作站上还不错,不够用后也挺适合挂在服务器上使用的由于天然只占pcie x8,因此很配8700g这种pcie通道有限的apu平台.

### 使用计划

4060Ti16G一发售就被游戏玩家称之为智商检测卡,但它是消费级显卡中唯一一张显存有16g的200w以下的n卡,而且发售时间比较近没什么矿卡价钱相对还算合理,功耗算力也还不错,因此其实很多工作室拿它来作为入门生产力显卡使用.我买它也是想作为家里生产力卡的,买它是因为家里台式机主板坏了,更新主机时一并更新的.现在对它的规划是在保修期(3年)内给主力机用,3年后换下来给itx(和8700g一起).

唯一遗憾的是这个型号没有18cm以内的正规短卡,所以我在买的时候就考虑到后续进itx要改短,就买了个同德公版的丐卡,同时买了3060ti的同德散热器,等过保就拆了改短.

这张卡显然是一张过渡卡,先在主力工作站上用,等不能满足工作站需求了就换下来给家用服务器用.其实市面上并不是没有其他可以替代的卡,有一张48g的4090/4090d,可以在linux下刷第三方驱动实现双卡互联,而且有aio水冷版本,完全可以用于训练14b以下的模型,也很适合用于生图生视频,它就更适合给工作站用;有一张卡它只有16cm,半高双槽,性能与4060ti相当且显存有20G,但功耗只有70w由pcie供电,这就是[RTX 4000 sff ada](https://www.nvidia.com/en-us/design-visualization/rtx-4000-sff/),但它卖8500,实在是太没有性价比了,等过几年看看小黄鱼有没有的淘一个给服务器用.

## AMD MI50 32G

这是一张老卡了,随着大船靠岸,这张卡的价格已经跌到了900以下的水平.由于这是一张计算卡,它是没有主动散热的,可以花100元不到改造成涡轮卡,然后限制功耗到160w以内就可以在正常家用主机上使用了.1000不到的价格买一张32g显存的计算卡,性价比还是挺高的,就算买了收藏感觉都值了.这张卡算是冲动消费的结果.

### 基本规格

介绍下[这块GPU的基本规格](https://www.amd.com/zh-cn/support/downloads/drivers.html/accelerators/instinct/instinct-mi-series/instinct-mi50-32gb.html).

这张卡是Vega20架构的计算卡,采用7nm工艺

+ 峰值半精度(FP16)性能为26.5 TFLOPs
+ 峰值INT8性能为53 TOPs
+ 32 GB的HBM2显存,支持ECC
+ 4096-bit的显存位宽,峰值显存带宽为1 TB/s
+ 默认满载功耗300w,默认限制功耗为220w
+ 支持PCIe 4.0 x16
+ 支持ROCm计算平台(官方仅支持到6.3版本,但可以通过非官方方式使用到6.4.3版本)
+ 没有视屏输出功能

### 特性分析

它的最大优势是显存大而且显存带宽极高,但它的缺点是算力不行,而且功耗也不低.还没主动散热,涡轮改造件其实并不能很好的压住满功耗运转的这张卡,需要限制功耗到160w以下才不至于过热影响使用寿命.这会使性能下降约10%左右.

这卡最适合的使用场景是大模型输入短上下文,输出长上下文的推理场景.比如文本扩写,代码生成等.而且天然适合用有thinking模式(深度思考)的模型.

### 使用计划

这张卡现在放在我的工作站上,主要用于借助llama.cpp的vulkan后端跑一些用于深度思考的大模型推理任务.而且amd的显卡虽然没有cuda,但意外的在opencl,opengl支持上还不错,跑一些专业软件,比如达芬奇(感谢苹果),反而有优势

这张卡的使用计划是放在工作站上用到淘汰,毕竟HBM2显存坏了基本就废了,而且300w的满载功耗也不适合长期使用.等到淘汰如果还没坏,考虑给它配个oculink显卡坞用于给mini主机外接使用.

## 补充

对于折腾过程中linux操作系统相关的内容,可以看我的[Ubuntu折腾记系列].讲道理现在越来越觉得linux桌面环境也挺好用的.

## 资料

+ [显卡天梯图](http://45592.com/)
+ [cpu性能对比](https://mail.openbenchmarking.org/vs/Processor/AMD+Ryzen+9+9950X+16-Core,Intel+Core+Ultra+9+285K)
+ [APU的BIOS相关教程](https://flowus.cn/lizong/share/b2bde652-83e6-4017-9a43-eaeffd2007bf)