---
layout: post
title: "在780m核显上的AI生态探索"
series:
    aipc_experiment:
        index: 4
date: 2025-01-02
author: "Hsz"
category: experiment
tags:
    - Linux
    - AIPC
    - Rocm
    - AIGC
    - LLM
    - TTS
    - Voice
    - Stable Diffusion
header-img: "img/home-bg-o.jpg"
update: 2025-01-02
---
# 在780m核显上的AI生态探索

780m这颗核显在笔记本平台基本已经证明了它的实力--默频约等于1050ti,小超约等于1650,极限超可以摸到1060屁股.我们且不考虑性能.先让它可以被机器学习相关工具调用起来.这也算是一窥amd的AI相关生态.

我们的验证平台是8700g,ubuntu 24.04.在前文中已经安装好了驱动和rocm,现在正式开始探索之旅.

## 核显ai生态的基础

我们都知道核显的显存就是内存,一般正常的主板bios最多给你分配16g内存作为核显的显存.当然16g并不算少,但对于很多情况来说也不多.好在[linux在内核版本`6.10`开始允许为核显分配更多的内存作为GTT内存参与核显运算](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=v6.10-rc4&id=eb853413d02c8d9b27942429b261a9eef228f005)

这里解释下现代核显的内存模型.对于核显来说,它并没有自己的显存(`vram`),因此只能从物理内存中"划一块"当作显存使用.因此我们的物理内存就有了两块组成`vram`(核显显存)和`ram`(内存).这两块虽然在物理层面是一样的,但使用时井水不犯河水--`vram`是核显专用,`ram`是cpu专用,这两者由于运作机制不同,数据封装等都不相同,因此即便是想也无法直接混用.但很多时候显存并不够用,这时我们就会希望要是能从`ram`(内存)再分点显存用用就好了.这个再分点给显存的部分就是[GTT内存](https://en.wikipedia.org/wiki/Graphics_address_remapping_table).`GTT`一旦被划分出去那就和`vram`一样不再属于`ram`了也就是成了核显专用的了.`GTT`和`vram`在使用时大体上是没有区别的,他们之间的区别主要是

| 区别 | `VRAM`                   | `GTT`                               |
| ---- | ------------------------ | ----------------------------------- |
| 来源 | 由bios设置划分           | 由操作系统划分                      |
| 性能 | 显示需要的内存性能会更好 | 由于无法直达Framebuffer因此会略差些 |

linux内核的这一特性默认会为`vram`和`GTT`一共划分一半的内存,而且这个容量是可以设置的,比如假如我们有64g的内存,我们想划分48g给`GTT`用可以通过编辑`/etc/modprobe.d/ttm.conf`来调整(以4k页为单位对于48G来说就是)

```txt
ttm pages_limit=12582912
ttm page_pool_size=12582912
```

因此我们完全可以在bios中的将`VRAM`设置为`auto`(默认为512m)让核显的`vram`仅用于显示,计算就全靠`GTT`.

这个特性刚出来半年,很多软件并没有很好的适配,但很显然,这种白占大显存的便宜很快就会跟上的.

当然你要说缺陷那自然也是有缺陷的.我们本质上还是在物理内存上划一块给显卡用,和apu最早的愿景--统一内存寻址还是有很大区别.但相比起apple的黄金内存,英伟达的振金显存,这各方案成本太低了.

## 基座运算库

基座运算库有多重要看看老黄赚多少就知道了.cuda早已占据了最好的生态位,这让amd和英特尔的显卡包括核显都很难受.

回到我们的主题,在linux环境下的780m上我们能用的基座运算库有

+ [rocm](https://github.com/ROCm/ROCm)
+ [zluda v3](https://github.com/vosen/ZLUDA/tree/v3)

他们都处在一个没什么支持的环境下.这就太难了.



### rocm



## pytorch的rocm支持

我们专门创建一个mamba环境来验证pytorch的支持

1. 在`~/mambaenvs`目录下创建`py3_11_rocm.yml`文件

    ```yml
    name: py3.11_rocm
    channels:
    - conda-forge
    dependencies:
    - python ~=3.11.10
    - jupyter
    - jupyterlab
    - ipywidgets
    - ipyparallel
    ```

    目前`py3.11`是ai生态支持比较广泛的python版本,我们以它为基准版本

2. 创建mamba虚拟环境

    ```bash
    mamba create -f py3_11_rocm.yml
    ```

3. 激活环境安装绑定rocm的pytorch

    ```bash
    mamba activate py3.11_rocm
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2
    ```

4. 验证安装成功

    进入python交互环境,执行

    ```python
    import torch
    x = torch.rand(5, 3)
    print(x)
    ```

    打印出类似

    ```pyhton
    tensor([[0.3380, 0.3845, 0.3217],
        [0.8337, 0.9050, 0.2650],
        [0.2979, 0.7141, 0.9069],
        [0.1449, 0.1132, 0.1375],
        [0.4675, 0.3947, 0.1426]])
    ```

    的内容说明pytorch安装没有问题.

    执行

    ```python
    torch.cuda.is_available()
    ```

    返回`True`说明rocm可用

5. 验证效果

    随便找个目录,拉个例子来跑下,验证下gpu确实被调用

    ```bash
    cd ~/workspace/test
    git clone https://github.com/pytorch/examples.git
    cd examples/mnist
    setproxy # 注意得挂代理
    python main.py
    ```

    打开`任务中心`查看GPU占用,如果能用起来说明rocm确实的被打开了

## huggingface的rocm支持

```bash
pip install transformers

```

换源[hf-mirror](https://hf-mirror.com/)

环境变量

```bash
#========================================================================== huggingface
export HF_ENDPOINT=https://hf-mirror.com
export HF_HUB_CACHE="~/.cache/huggingface/hub"
```

我们的显卡是780m,支持非常有限,官方宣传的`Flash Attention`只有amd的服务器GPU支持,`GPTQ`只支持到了`rocm5.7`且基本已经停止了对rocm的支持.而`onnxruntme`目前只支持到`rocm6.0`.

amd的方案本来就是小众,rocm只能在linux下使用那就更是小众中的小众了非常遗憾.

好在这些基本都是推理侧优化,问题没那么大

## llm支持

### llama.cpp

#### lora训练

### ollama

作为llama.cpp的上层管理工具,ollama自然是可以顺利执行的,我们要让igpu成为默认选项,需要做如下设置:

1. 先停掉`ollama`

    ```bash
    sudo systemctl stop ollama.service
    ```

2. 进入systemd的设置页设置ollama.service的启动环境(一般文件都还没有,需要创建)

    ```bash
    sudo su
    cd /etc/systemd/system/
    mkdir ollama.service.d
    cd ollama.service.d
    nano override.conf
    ```

    填入如下内容

    ```bash
    [Service]
    Environment="HSA_OVERRIDE_GFX_VERSION=11.0.0" # 780m
    Environment="OLLAMA_MAX_LOADED_MODELS=1" # 仅加载一个模型
    Environment="OLLAMA_NUM_PARALLEL=1" # 仅允许一个并发
    ```

    当然了如果有其他要设置的也在这里设置,设置项可以用`ollama serve --help`查看

3. 重新加载ollama.service的设置,并重启

    ```bash
    sudo systemctl daemon-reload
    sudo systemctl restart ollama.service
    ```

但至少截止到2025年01月07日的主干版本为止还存在问题:

当我们要运行一个大模型时,ollama会根据`vram`的大小来判断是否要让cpu参与推理,参与的程度就是

```bash
(模型大小-vram):vram=cpu:gpu
```

但很尴尬的是实际在gpu中执行时又都是放在`GTT`中执行的,`vram`一点都不会被用到.详情可以参考这个[issus](https://github.com/ollama/ollama/issues/5471)和这个[pull request](https://github.com/ollama/ollama/pull/6282),作者还提供了一个补丁,只是还没被合进主干.

## aigc支持

### comfyui

https://github.com/comfyanonymous/comfyui/issues/2810

https://github.com/vosen/ZLUDA/tree/v3

https://www.bilibili.com/video/BV1x2421F78A/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=c998bf096c14b49524fadf64ec3e75c8

### lora训练

## docker支持

amd提供了[一系列docker镜像](https://hub.docker.com/u/rocm),我们需要根据自己的rocm版本(最后一位可以不匹配)以及用到的环境选对应后缀的.

需要注意rocm的docker支持需要宿主机安装好rocm,且镜像rocm和宿主机的匹配

```bash
docker run -it --device=/dev/kfd --device=/dev/dri --group-add video rocm/rocm-terminal:6.2.1
```

比较常用的镜像包括

+ [rocm/onnxruntime](https://hub.docker.com/r/rocm/onnxruntime),onnxruntime环境,可以选onnxruntime版本和pytorch版本,一般用来做推理侧应用
+ [rocm/pytorch](https://hub.docker.com/r/rocm/pytorch/tags),pytorch环境,后缀可以选ubuntu版本,一般用来做训练和开发,也是最常用的镜像
+ [dev-ubuntu-24.04](https://hub.docker.com/r/rocm/dev-ubuntu-24.04)和[ocm/dev-ubuntu-22.04](https://hub.docker.com/r/rocm/dev-ubuntu-22.04),带rocm的ubuntu环境,一般用来做底层框架
<!-- + [rocm/rocm-terminal](https://hub.docker.com/r/rocm/rocm-terminal),rocm的最小镜像,仅包含与宿主机连接rocm的环境,连操作系统都没有.一般也就用来测试.
 -->

我们以`rocm/pytorch`举例

```bash
docker pull rocm/pytorch:rocm6.2.3_ubuntu22.04_py3.10_pytorch_release_2.3.0_triton_llvm_reg_issue

docker run -it --device /dev/kfd --device /dev/dri --security-opt seccomp=unconfined rocm/pytorch:rocm6.2.3_ubuntu22.04_py3.10_pytorch_release_2.3.0_triton_llvm_reg_issue
```

注意这个镜像极大,有20G以上,对网络有很高的要求

<!-- todo -->